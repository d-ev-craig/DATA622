import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

data = pd.read_csv("data/train_v2_drcat_02.csv")

X = data['text']
y = data['prompt_name']

target_names = y.unique()



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .4, random_state = 42)

vectorizer = TfidfVectorizer(
    sublinear_tf=True, max_df=0.5, min_df=5, stop_words="english"
)

Vec_X_train = vectorizer.fit_transform(X_train)
Vec_X_test = vectorizer.transform(X_test)





from sklearn.linear_model import RidgeClassifier
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# Establish our RidgeClassifier
clf = RidgeClassifier(tol=1e-2, solver="sparse_cg")

# Fit Ridge to data
clf.fit(Vec_X_train, y_train)

# Make predictions
pred = clf.predict(Vec_X_test)

# Start plot
fig, ax = plt.subplots(figsize=(10, 5))

# Confusion Matrix Disply has a method 'from_predictions' that allow you to reference predictions and actual values directly
ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)
ax.xaxis.set_ticklabels(target_names) # Establishing tick labels from the groups
ax.yaxis.set_ticklabels(target_names) 
_ = ax.set_title(
    f"Confusion Matrix for {clf.__class__.__name__}" # Referencing our classifier object's name directly
)
plt.xticks(rotation='vertical')





avg_vals = np.asarray(X_train.mean(axis=0)).ravel()

avg_vals




#borked code

import numpy as np

feature_names = vectorizer.get_feature_names_out() # Pull out the specific words used to classify the docs

def plot_feature_effects():

    # learned coefficients weighted by frequency of appearance
    # X_train.mean(axis=0) calculates the mean of each column, it does this by adding a column's values BY ROW, hence axis=0, then dividing by num of rows
    # X_train is our vectorized values of each word in the text blurb
    # .ravel() flattens a multidimensional array into a 1d array
    # We multiply the array of the average vectorized values by clf.coef_ to find the average weight
    average_feature_effects = clf.coef_ * np.asarray(X_train.mean(axis=0)).ravel()

    for i, label in enumerate(target_names):
        top5 = np.argsort(average_feature_effects[i])[-5:][::-1]
        if i == 0:
            top = pd.DataFrame(feature_names[top5], columns=[label])
            top_indices = top5
        else:
            top[label] = feature_names[top5]
            top_indices = np.concatenate((top_indices, top5), axis=None)
    top_indices = np.unique(top_indices)
    predictive_words = feature_names[top_indices]

    # plot feature effects
    bar_size = 0.25
    padding = 0.75
    y_locs = np.arange(len(top_indices)) * (4 * bar_size + padding)

    fig, ax = plt.subplots(figsize=(10, 8))
    for i, label in enumerate(target_names):
        ax.barh(
            y_locs + (i - 2) * bar_size,
            average_feature_effects[i, top_indices],
            height=bar_size,
            label=label,
        )
    ax.set(
        yticks=y_locs,
        yticklabels=predictive_words,
        ylim=[
            0 - 4 * bar_size,
            len(top_indices) * (4 * bar_size + padding) - 4 * bar_size,
        ],
    )
    ax.legend(loc="lower right")

    print("top 5 keywords per class:")
    print(top)

    return ax


_ = plot_feature_effects().set_title("Average feature effect on the original data")